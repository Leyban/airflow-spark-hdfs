{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import re\n",
    "from hashlib import sha1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporary Postgres Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "ONLINE_BANK_ACCOUNT_TABLE = \"online_bank_data\"\n",
    "engine_payment = create_engine(\"postgresql://airflow:airflow@localhost:5432/paymentDB\")\n",
    "\n",
    "postgres_options = {\n",
    "    \"database\":\"paymentDB\",\n",
    "    \"host\":'172.17.0.1',\n",
    "    \"user\":'airflow',\n",
    "    \"password\":'airflow',\n",
    "    \"port\":'5432'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VTB_TMO_URL = 'https://api.louismmoo.com/api/viettinbank/transactions' \n",
    "PROVIDER_NONE = 0\n",
    "PROVIDER_TMO = 1\n",
    "\n",
    "VIETINBANK_CODE = 'VTB'\n",
    "\n",
    "PAYMENT_TYPE_DLBT = \"DLBT\"\n",
    "PAYMENT_TYPE_DLBT60 = \"DLBT60\"\n",
    "\n",
    "BANK_ACCOUNT_STATUS_ACTIVE = 1\n",
    "BANK_ACC_AUTO_STATUS = 2\n",
    "\n",
    "BANK_ACCOUNT_TABLE = 'bank_account'\n",
    "ONLINE_BANK_ACCOUNT_TABLE = 'online_bank_data'\n",
    "DEPOSIT_TABLE = 'deposit'\n",
    "\n",
    "DEPOSIT_LOG_TABLE ='deposit_log'\n",
    "\n",
    "DEPOSIT_STATUS_PROCESSING = 1\n",
    "DEPOSIT_STATUS_FAILED = 3\n",
    "DEPOSIT_STATUS_REVIEWED = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Bank Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bank_acc():\n",
    "      # conn_payment_pg_hook = PostgresHook(postgres_conn_id='payment_conn_id')\n",
    "\n",
    "      rawsql = f\"\"\"\n",
    "            SELECT \n",
    "            ba.login_name as  username,\n",
    "            ba.password,\n",
    "            ba.account_no,\n",
    "            ba.provider,\n",
    "            ba.id  as bank_account_id ,\n",
    "            b.code as bank_code,\n",
    "            b.id as bank_id\n",
    "            FROM bank_account AS ba \n",
    "            LEFT JOIN bank AS b ON b.id = ba.bank_id \n",
    "            WHERE auto_status = '{BANK_ACC_AUTO_STATUS}' \n",
    "            AND status = '{BANK_ACCOUNT_STATUS_ACTIVE}'\n",
    "      \"\"\"\n",
    "            \n",
    "      # bank_acc_df = conn_payment_pg_hook.get_pandas_df(rawsql)\n",
    "            \n",
    "      # Temp <<========================================\n",
    "      with psycopg2.connect( **postgres_options ) as conn:\n",
    "            sql = rawsql\n",
    "            bank_acc_df = pd.read_sql_query(sql, conn)\n",
    "            \n",
    "      conn.close()\n",
    "      # ========================================>> Temp \n",
    "\n",
    "      return bank_acc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Old Data from Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_online_bank_df(date_from, date_to):\n",
    "    begin_str = date_from.strftime(\"%m/%d/%Y\")\n",
    "    end_str = date_to.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    rawsql = f\"\"\"\n",
    "        SELECT \n",
    "            hash_id\n",
    "        FROM online_bank_data as d\n",
    "        WHERE CAST (transaction_date AS DATE) >= '{begin_str}' \n",
    "        AND CAST (transaction_date AS DATE) <= '{end_str}' \n",
    "    \"\"\"\n",
    "\n",
    "    # df = conn_payment_pg_hook.get_pandas_df(rawsql)\n",
    "\n",
    "    # Temp <<========================================\n",
    "    df = pd.DataFrame()\n",
    "    with psycopg2.connect( **postgres_options ) as conn:\n",
    "        df = pd.read_sql_query(rawsql, conn)\n",
    "            \n",
    "    conn.close()\n",
    "    # ========================================>> Temp \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hash(row):\n",
    "    hash_input = (\n",
    "        str( row['bank_reference'] ) +\n",
    "        str( row['bank_description'] ) +\n",
    "        str( row['net_amount'] ) +\n",
    "        str( row['transaction_date'].day ) +\n",
    "        str( row['transaction_date'].month ) +\n",
    "        str( row['transaction_date'].year )\n",
    "    )\n",
    "    return sha1(hash_input.encode('utf-8')).hexdigest()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Via TMO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_VTB_TMO_data(username,password,accountNumber,begin,end, page):\n",
    "    import json\n",
    "\n",
    "    params = {\n",
    "        \"username\":username,\n",
    "        \"password\":password ,\n",
    "        \"accountNumber\":accountNumber,\n",
    "        \"begin\":begin,\n",
    "        \"end\":end,\n",
    "        \"page\":page\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(params)\n",
    "    \n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    req =requests.post(\n",
    "        VTB_TMO_URL, \n",
    "        data = payload,\n",
    "        headers = headers\n",
    "    )\n",
    "    result = req.json().get('data',{}).get('transactions', [])\n",
    "    \n",
    "    trans_df = pd.DataFrame.from_records(result)  \n",
    "\n",
    "    if trans_df.empty:\n",
    "        return trans_df\n",
    "\n",
    "    new_bank_df = trans_df.loc[:, ['trxId','remark','amount','processDate']]\n",
    "    new_bank_df = new_bank_df.rename(columns={\n",
    "        'trxId': 'bank_reference',\n",
    "        'remark':'bank_description',\n",
    "        'amount':'net_amount',\n",
    "        'processDate':'transaction_date'\n",
    "    })\n",
    "\n",
    "    return new_bank_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Each Bank Account Fetch Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_online_bank_data(date_from,date_to):\n",
    "    begin_str = date_from.strftime(\"%d/%m/%Y\")\n",
    "    end_str = date_to.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    bank_acc_df = extract_bank_acc()\n",
    "    \n",
    "    for _, row in bank_acc_df.iterrows():\n",
    "        page = 0\n",
    "        while row['username']!= None and row['password']!= None and row['account_no']!= None and row['provider'] > PROVIDER_NONE:\n",
    "            print(\"Fetching \", row['bank_code'], \" with Provider:\", row['provider'], \" Data for Page \", page)\n",
    "            print( row['username'], row['password'], row['account_no'], begin_str, end_str, page)\n",
    "\n",
    "            new_bank_df = pd.DataFrame()\n",
    "\n",
    "            if row['bank_code'] == VIETINBANK_CODE.lower():\n",
    "                if row['provider'] == PROVIDER_TMO:\n",
    "                    print(\"Fetching VTB Data via TMO\")\n",
    "                    trans_df = fetch_VTB_TMO_data(\n",
    "                        row['username'], \n",
    "                        row['password'], \n",
    "                        row['account_no'],\n",
    "                        begin_str, \n",
    "                        end_str,\n",
    "                        page\n",
    "                    )\n",
    "                    new_bank_df = trans_df\n",
    "\n",
    "            if new_bank_df.empty:\n",
    "                print(\"No Data Received\")\n",
    "                break\n",
    "\n",
    "            new_bank_df['bank_account_id'] = row['bank_account_id']\n",
    "            new_bank_df['bank_id'] = row['bank_id']\n",
    "\n",
    "            new_bank_df['transaction_date'] = pd.to_datetime(new_bank_df['transaction_date'], format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "            new_bank_df['hash_id'] = new_bank_df.apply(compute_hash, axis=1)\n",
    "\n",
    "            print('New Data Count: ', new_bank_df.shape[0])\n",
    "\n",
    "            old_bank_df = get_old_online_bank_df(date_from, date_to)\n",
    "\n",
    "            bank_df = new_bank_df[~new_bank_df['hash_id'].isin(old_bank_df['hash_id'])]\n",
    "            if bank_df.empty:\n",
    "                print(\"All New Data are found in DB: Terminating Fetching\")\n",
    "                break\n",
    "            \n",
    "            print(\"Inserting into DB: \", bank_df.shape[0])\n",
    "\n",
    "            bank_df.to_sql(ONLINE_BANK_ACCOUNT_TABLE, con=engine_payment, if_exists='append', index=False)\n",
    "\n",
    "            page += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch online bank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_bank_data(begin, end):\n",
    "    rawsql = f\"\"\"\n",
    "        SELECT \n",
    "            id as online_bank_data_id,\n",
    "            bank_account_id,\n",
    "            bank_id,\n",
    "            bank_reference,\n",
    "            bank_description,\n",
    "            net_amount as amount\n",
    "        FROM online_bank_data as d\n",
    "        WHERE deposit_id  = 0\n",
    "        AND CAST (transaction_date as DATE) >= '{begin}'\n",
    "        AND CAST (transaction_date as DATE) <= '{end}'\n",
    "    \"\"\"\n",
    "    \n",
    "    # df = conn_payment_pg_hook.get_pandas_df(rawsql)\n",
    "    # Temp <<========================================\n",
    "    df = pd.DataFrame()\n",
    "    with psycopg2.connect( **postgres_options ) as conn:\n",
    "        df = pd.read_sql_query(rawsql, conn)\n",
    "            \n",
    "    conn.close()\n",
    "    # ========================================>> Temp \n",
    "\n",
    "    df = df.rename(columns={'net_amount': 'amount'})\n",
    "    df['amount'] = pd.to_numeric(df['amount']) \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Deposits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deposits():\n",
    "    # conn_payment_pg_hook = PostgresHook(postgres_conn_id='payment_conn_id')\n",
    "\n",
    "    rawsql = f\"\"\"\n",
    "          SELECT \n",
    "                id as deposit_id,\n",
    "                bank_account_id,\n",
    "                transaction_id,\n",
    "                ref_code,\n",
    "                net_amount as amount,\n",
    "                payment_type_code,\n",
    "                login_name,\n",
    "                status\n",
    "        FROM deposit \n",
    "        WHERE ( payment_type_code = '{PAYMENT_TYPE_DLBT}' OR payment_type_code = '{PAYMENT_TYPE_DLBT60}' )\n",
    "        AND status = {DEPOSIT_STATUS_PROCESSING} \n",
    "    \"\"\"\n",
    "\n",
    "    # df = conn_payment_pg_hook.get_pandas_df(rawsql)\n",
    "    # Temp <<========================================\n",
    "    df = pd.DataFrame()\n",
    "    with psycopg2.connect( **postgres_options ) as conn:\n",
    "        df = pd.read_sql_query(rawsql, conn)\n",
    "            \n",
    "    conn.close()\n",
    "    # ========================================>> Temp \n",
    "\n",
    "    return df\n",
    "\n",
    "def get_bank_accounts():\n",
    "    # conn_payment_pg_hook = PostgresHook(postgres_conn_id='payment_conn_id')\n",
    "\n",
    "    rawsql = f\"\"\"\n",
    "        SELECT \n",
    "            id as bank_account_id,\n",
    "            bank_id,\n",
    "            account_no\n",
    "        FROM bank_account\n",
    "        WHERE auto_status = {BANK_ACC_AUTO_STATUS}\n",
    "    \"\"\"\n",
    "\n",
    "    # df = conn_payment_pg_hook.get_pandas_df(rawsql)\n",
    "    # Temp <<========================================\n",
    "    df = pd.DataFrame()\n",
    "    with psycopg2.connect( **postgres_options ) as conn:\n",
    "        df = pd.read_sql_query(rawsql, conn)\n",
    "            \n",
    "    conn.close()\n",
    "    # ========================================>> Temp \n",
    "\n",
    "    return df\n",
    "\n",
    "def get_banks():\n",
    "    # conn_payment_pg_hook = PostgresHook(postgres_conn_id='payment_conn_id')\n",
    "\n",
    "    rawsql = f\"\"\"\n",
    "        SELECT \n",
    "            id as bank_id,\n",
    "            code as bank_code\n",
    "        FROM bank\n",
    "    \"\"\"\n",
    "\n",
    "    # df = conn_payment_pg_hook.get_pandas_df(rawsql)\n",
    "    # Temp <<========================================\n",
    "    df = pd.DataFrame()\n",
    "    with psycopg2.connect( **postgres_options ) as conn:\n",
    "        df = pd.read_sql_query(rawsql, conn)\n",
    "            \n",
    "    conn.close()\n",
    "    # ========================================>> Temp \n",
    "\n",
    "    return df\n",
    "\n",
    "def get_valid_deposits():\n",
    "    deposit_df = get_deposits()\n",
    "\n",
    "    bank_acc_df = get_bank_accounts() \n",
    "\n",
    "    merged_df = deposit_df.merge(bank_acc_df, 'left', 'bank_account_id')\n",
    "\n",
    "    bank_df = get_banks()\n",
    "\n",
    "    merged_df = merged_df.merge(bank_df, 'left', 'bank_id')\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Deposit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_deposit_df(deposit_df: pd.DataFrame):\n",
    "    deposit_df = deposit_df.dropna(subset=['bank_id'])\n",
    "    deposit_df.drop_duplicates(subset=['ref_code', 'amount', 'bank_account_id', 'bank_code'], keep='first', inplace=True)\n",
    "\n",
    "    return deposit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(word,string):\n",
    "    match_string = r'\\b' + word + r'\\b'\n",
    "    return bool(re.search(match_string, string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_vtb(x):\n",
    "    cd1 = (x['bank_code'] == VIETINBANK_CODE.lower())\n",
    "\n",
    "    cd2 = (x['amount_x'] == x['amount_y'])\n",
    "\n",
    "    # cd3 = match(str(x['ref_code']),str(x['bank_reference']).replace('credit','').replace(',','')) & (len(x['ref_code']) >=12)\n",
    "    cd3 = match(str(x['ref_code']),str(x['bank_description']))\n",
    "\n",
    "    return cd1 & cd2 & cd3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched(deposit_df, bank_df):\n",
    "    deposit_df = deposit_df.rename(columns={'amount':'amount_x'})\n",
    "    bank_df = bank_df.rename(columns={'amount':'amount_y'})\n",
    "    bank_df['amount_y'] = round(bank_df['amount_y'].astype(float) * 0.001, 5)\n",
    "\n",
    "    merged = pd.merge(deposit_df, bank_df, how='left', on=['bank_id', 'bank_account_id'])\n",
    "    \n",
    "    conditions = lambda x: filter_vtb(x)\n",
    "\n",
    "    merged['result'] = merged.apply(lambda x: conditions(x), axis=1) \n",
    "    new_merged_df = merged[merged['result']]\n",
    "\n",
    "    # Cleaning\n",
    "    new_merged_df = new_merged_df.drop_duplicates(subset=['deposit_id'])\n",
    "    new_merged_df['deposit_id'] = new_merged_df['deposit_id'].astype('int')\n",
    "    new_merged_df['online_bank_data_id'] = new_merged_df['online_bank_data_id'].astype('int')\n",
    "\n",
    "    return new_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Online Bank Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bank_data(merged_df):\n",
    "    print(\"Updating Online Bank Data: \", merged_df.shape[0])\n",
    "\n",
    "    sqls = []\n",
    "\n",
    "    for _, row in merged_df.iterrows():\n",
    "        update_online_bank_sql = f\"\"\"\n",
    "            UPDATE {ONLINE_BANK_ACCOUNT_TABLE} \n",
    "            SET deposit_id = '{row['deposit_id']}' ,\n",
    "                transaction_id = '{row['transaction_id']}'\n",
    "            WHERE id ='{row['online_bank_data_id']}' \n",
    "        \"\"\"\n",
    "\n",
    "        sqls.append(update_online_bank_sql)\n",
    "\n",
    "        # Temp <<========================================\n",
    "        with psycopg2.connect( **postgres_options ) as conn:\n",
    "            with conn.cursor() as curs:\n",
    "                curs.execute(update_online_bank_sql)\n",
    "        conn.close()\n",
    "        # ========================================>> Temp \n",
    "\n",
    "    # conn_payment_pg_hook.run(sqls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Online Bank Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_OBD(**context):\n",
    "    try:\n",
    "        date_to = datetime.utcnow()\n",
    "        date_from = date_to - timedelta(hours=3)\n",
    "\n",
    "        # Taking Optional Date Parameters\n",
    "        date_format = '%Y-%m-%d %H:%M:%S'\n",
    "        if 'date_from' in context['params']:\n",
    "            date_from = datetime.strptime(context['params']['date_from'], date_format)\n",
    "        \n",
    "        if 'date_to' in context['params']:\n",
    "            date_to = datetime.strptime(context['params']['date_to'], date_format)\n",
    "\n",
    "        print(\"Updating Onlne Bank Data\")\n",
    "        update_online_bank_data(date_from, date_to)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"An error occurred:\", type(error).__name__, \"-\", error)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_deposit(**context):\n",
    "    date_to = datetime.utcnow()\n",
    "    date_from = date_to - timedelta(hours=3)\n",
    "\n",
    "    # Taking Optional Date Parameters\n",
    "    date_format = '%Y-%m-%d %H:%M:%S'\n",
    "    if 'date_from' in context['params']:\n",
    "        date_from = datetime.strptime(context['params']['date_from'], date_format)\n",
    "    \n",
    "    if 'date_to' in context['params']:\n",
    "        date_to = datetime.strptime(context['params']['date_to'], date_format)\n",
    "\n",
    "    print(\"Getting Online Bank Data\")\n",
    "    bank_df = get_online_bank_data(date_from, date_to)\n",
    "    if bank_df.empty:\n",
    "        print(\"No Bank Data Found\")\n",
    "        return\n",
    "\n",
    "    print(\"Getting Deposits\")\n",
    "    deposit_df = get_valid_deposits()\n",
    "    if deposit_df.empty:\n",
    "        print(\"No Deposits Found\")\n",
    "        return\n",
    "    \n",
    "    print(\"Cleaning Deposit\")\n",
    "    filtered_deposit_df = clean_deposit_df(deposit_df)\n",
    "    if filtered_deposit_df.empty:\n",
    "        print(\"No Valid Deposits Found\")\n",
    "        return\n",
    "\n",
    "    print(\"Merging Deposit and Bank Dataframes\")\n",
    "    merged = get_matched(filtered_deposit_df, bank_df)\n",
    "    if merged.empty:\n",
    "        print(\"No Match Found\")\n",
    "        return\n",
    "    \n",
    "    update_bank_data(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\n",
    "    'params': {\n",
    "        \"date_from\":\"2023-09-08 00:00:00\",\n",
    "        \"date_to\":\"2023-09-27 23:59:59\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Onlne Bank Data\n",
      "Fetching  vtb  with Provider: 1  Data for Page  0\n",
      "0843501988 Err7412! 103878535119 08/09/2023 27/09/2023 0\n",
      "Fetching VTB Data via TMO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35967/4275329575.py:24: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  bank_acc_df = pd.read_sql_query(sql, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Count:  100\n",
      "All New Data are found in DB: Terminating Fetching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35967/3042553882.py:18: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(rawsql, conn)\n"
     ]
    }
   ],
   "source": [
    "update_OBD(**context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Online Bank Data\n",
      "Getting Deposits\n",
      "Cleaning Deposit\n",
      "Merging Deposit and Bank Dataframes\n",
      "No Match Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35967/1745594611.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(rawsql, conn)\n",
      "/tmp/ipykernel_35967/3016397187.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(rawsql, conn)\n",
      "/tmp/ipykernel_35967/3016397187.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(rawsql, conn)\n",
      "/tmp/ipykernel_35967/3016397187.py:66: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(rawsql, conn)\n"
     ]
    }
   ],
   "source": [
    "auto_deposit(**context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
